{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5453a127",
   "metadata": {},
   "source": [
    "### Step forward feature selection\n",
    "\n",
    "Step forward feature selection starts by training a machine learning model for each feature in the dataset and selects, as the starting feature, the one that returns the best performing model, according to a certain evaluation criteria we choose.\n",
    "\n",
    "In the second step, it creates machine learning models for all combinations of the feature selected in the previous step and a second feature. It selects the pair that produces the best performing algorithm.\n",
    "\n",
    "It continues by adding 1 feature at a time to the features that were pre-selected in previous steps, until a pre-determined stopping criteria.\n",
    "\n",
    "In theory, models with more features, perform better. The algorithm will continue adding new features until a criteria is met. For example, until the model performance does not increase beyond a certain threshold. Or, as implemented in the library we will discuss in this notebook, until a certain number of features is selected.\n",
    "\n",
    "The model performance metric can be the roc_auc for classification and the r_\n",
    "squared for regression for example, and it is determined by the user. \n",
    "\n",
    "Step forward feature selection is called a greedy procedure, because it evaluates many possible single, double, triple and so on feature combinations. Therefore, it is very computationally expensive, and sometimes, if the feature space is big, even unfeasible.\n",
    "\n",
    "There is a special package in Python that implements this type of feature selection: mlxtend.\n",
    "http://rasbt.github.io/mlxtend/\n",
    "\n",
    "In the mlxtend implementation of the Step Forward Feature Selection, the stopping criteria is an arbitrarily set number of features. So the search will finish when we reach the desired number of selected features.\n",
    "\n",
    "This is somewhat arbitrary, we might be selecting a sub-opimal number of features, or likewise, a high number of features. But, by looking at the performance metric returned by the algorithm as it selects the features, we can have a view, if more features do add value, or not. \n",
    "\n",
    "\n",
    "**Note**\n",
    "If we wanted to stop the search by using another criteria, we would have to code the algorithm ourselves, unfortunately :(\n",
    "\n",
    "Here I will use the Step Forward feature selection algorithm from mlxtend in a classification and regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72566b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb35a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>var_10</th>\n",
       "      <th>...</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>var_107</th>\n",
       "      <th>var_108</th>\n",
       "      <th>var_109</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.532710</td>\n",
       "      <td>3.280834</td>\n",
       "      <td>17.982476</td>\n",
       "      <td>4.404259</td>\n",
       "      <td>2.349910</td>\n",
       "      <td>0.603264</td>\n",
       "      <td>2.784655</td>\n",
       "      <td>0.323146</td>\n",
       "      <td>12.009691</td>\n",
       "      <td>0.139346</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079066</td>\n",
       "      <td>6.748819</td>\n",
       "      <td>2.941445</td>\n",
       "      <td>18.360496</td>\n",
       "      <td>17.726613</td>\n",
       "      <td>7.774031</td>\n",
       "      <td>1.473441</td>\n",
       "      <td>1.973832</td>\n",
       "      <td>0.976806</td>\n",
       "      <td>2.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.821374</td>\n",
       "      <td>12.098722</td>\n",
       "      <td>13.309151</td>\n",
       "      <td>4.125599</td>\n",
       "      <td>1.045386</td>\n",
       "      <td>1.832035</td>\n",
       "      <td>1.833494</td>\n",
       "      <td>0.709090</td>\n",
       "      <td>8.652883</td>\n",
       "      <td>0.102757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.479789</td>\n",
       "      <td>7.795290</td>\n",
       "      <td>3.557890</td>\n",
       "      <td>17.383378</td>\n",
       "      <td>15.193423</td>\n",
       "      <td>8.263673</td>\n",
       "      <td>1.878108</td>\n",
       "      <td>0.567939</td>\n",
       "      <td>1.018818</td>\n",
       "      <td>1.416433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.938776</td>\n",
       "      <td>7.952752</td>\n",
       "      <td>0.972671</td>\n",
       "      <td>3.459267</td>\n",
       "      <td>1.935782</td>\n",
       "      <td>0.621463</td>\n",
       "      <td>2.338139</td>\n",
       "      <td>0.344948</td>\n",
       "      <td>9.937850</td>\n",
       "      <td>11.691283</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861487</td>\n",
       "      <td>6.130886</td>\n",
       "      <td>3.401064</td>\n",
       "      <td>15.850471</td>\n",
       "      <td>14.620599</td>\n",
       "      <td>6.849776</td>\n",
       "      <td>1.098210</td>\n",
       "      <td>1.959183</td>\n",
       "      <td>1.575493</td>\n",
       "      <td>1.857893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.020690</td>\n",
       "      <td>9.900544</td>\n",
       "      <td>17.869637</td>\n",
       "      <td>4.366715</td>\n",
       "      <td>1.973693</td>\n",
       "      <td>2.026012</td>\n",
       "      <td>2.853025</td>\n",
       "      <td>0.674847</td>\n",
       "      <td>11.816859</td>\n",
       "      <td>0.011151</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340944</td>\n",
       "      <td>7.240058</td>\n",
       "      <td>2.417235</td>\n",
       "      <td>15.194609</td>\n",
       "      <td>13.553772</td>\n",
       "      <td>7.229971</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>2.234482</td>\n",
       "      <td>0.946170</td>\n",
       "      <td>2.700606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.909506</td>\n",
       "      <td>10.576516</td>\n",
       "      <td>0.934191</td>\n",
       "      <td>3.419572</td>\n",
       "      <td>1.871438</td>\n",
       "      <td>3.340811</td>\n",
       "      <td>1.868282</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>13.585620</td>\n",
       "      <td>1.153366</td>\n",
       "      <td>...</td>\n",
       "      <td>2.738095</td>\n",
       "      <td>6.565509</td>\n",
       "      <td>4.341414</td>\n",
       "      <td>15.893832</td>\n",
       "      <td>11.929787</td>\n",
       "      <td>6.954033</td>\n",
       "      <td>1.853364</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>2.599562</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_1      var_2      var_3     var_4     var_5     var_6     var_7  \\\n",
       "0  4.532710   3.280834  17.982476  4.404259  2.349910  0.603264  2.784655   \n",
       "1  5.821374  12.098722  13.309151  4.125599  1.045386  1.832035  1.833494   \n",
       "2  1.938776   7.952752   0.972671  3.459267  1.935782  0.621463  2.338139   \n",
       "3  6.020690   9.900544  17.869637  4.366715  1.973693  2.026012  2.853025   \n",
       "4  3.909506  10.576516   0.934191  3.419572  1.871438  3.340811  1.868282   \n",
       "\n",
       "      var_8      var_9     var_10  ...   var_100   var_101   var_102  \\\n",
       "0  0.323146  12.009691   0.139346  ...  2.079066  6.748819  2.941445   \n",
       "1  0.709090   8.652883   0.102757  ...  2.479789  7.795290  3.557890   \n",
       "2  0.344948   9.937850  11.691283  ...  1.861487  6.130886  3.401064   \n",
       "3  0.674847  11.816859   0.011151  ...  1.340944  7.240058  2.417235   \n",
       "4  0.439865  13.585620   1.153366  ...  2.738095  6.565509  4.341414   \n",
       "\n",
       "     var_103    var_104   var_105   var_106   var_107   var_108   var_109  \n",
       "0  18.360496  17.726613  7.774031  1.473441  1.973832  0.976806  2.541417  \n",
       "1  17.383378  15.193423  8.263673  1.878108  0.567939  1.018818  1.416433  \n",
       "2  15.850471  14.620599  6.849776  1.098210  1.959183  1.575493  1.857893  \n",
       "3  15.194609  13.553772  7.229971  0.835158  2.234482  0.946170  2.700606  \n",
       "4  15.893832  11.929787  6.954033  1.853364  0.511027  2.599562  0.811364  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "data = pd.read_csv('..\\precleaned-datasets\\dataset_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b6f6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 109)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bae7f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 108), (15000, 108))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train and test\n",
    "# separate train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['target'], axis=1),\n",
    "    data['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbcbae9",
   "metadata": {},
   "source": [
    "### Remove Correlated features\n",
    "\n",
    "Step Forward Feature Selection takes a long time to run, so to speed it up we will reduce the feature space by removing correlated features first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a513e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  36\n"
     ]
    }
   ],
   "source": [
    "# remove correlated features to reduce the feature space\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3191a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 72), (15000, 72))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb088b2",
   "metadata": {},
   "source": [
    "### Step Forward Feature Selection\n",
    "\n",
    "For the Step Forward feature selection algorithm, we are going to use the class SFS from MLXtend:\n",
    "http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2fed2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:  1.5min finished\n",
      "\n",
      "[2022-06-02 10:59:56] Features: 1/10 -- score: 0.5772568300154471[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:  1.2min finished\n",
      "\n",
      "[2022-06-02 11:01:09] Features: 2/10 -- score: 0.5904783335465119[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:   41.9s finished\n",
      "\n",
      "[2022-06-02 11:01:51] Features: 3/10 -- score: 0.5930946010581912[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:   45.9s finished\n",
      "\n",
      "[2022-06-02 11:02:37] Features: 4/10 -- score: 0.5961029256813966[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:   48.4s finished\n",
      "\n",
      "[2022-06-02 11:03:26] Features: 5/10 -- score: 0.6409133259990374[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:   56.2s finished\n",
      "\n",
      "[2022-06-02 11:04:22] Features: 6/10 -- score: 0.6442710299806867[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:  1.0min finished\n",
      "\n",
      "[2022-06-02 11:05:23] Features: 7/10 -- score: 0.645737500827873[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:  1.1min finished\n",
      "\n",
      "[2022-06-02 11:06:28] Features: 8/10 -- score: 0.6475834569629563[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:  1.5min finished\n",
      "\n",
      "[2022-06-02 11:07:56] Features: 9/10 -- score: 0.6446743632289508[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:  1.5min finished\n",
      "\n",
      "[2022-06-02 11:09:24] Features: 10/10 -- score: 0.6542066775806803"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(cv=3,\n",
       "                          estimator=RandomForestClassifier(n_estimators=10,\n",
       "                                                           n_jobs=2,\n",
       "                                                           random_state=0),\n",
       "                          k_features=10, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# within the SFS we indicate:\n",
    "\n",
    "# 1) the algorithm we want to create, in this case RandomForests\n",
    "# (note that I use few trees to speed things up)\n",
    "\n",
    "# 2) the stopping criteria: want to select 10 features \n",
    "\n",
    "# 3) wheter to perform step forward or step backward\n",
    "\n",
    "# 4) the evaluation metric: in this case the roc_auc\n",
    "# 5) the cross-validation\n",
    "\n",
    "sfs = SFS(estimator=RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=2),\n",
    "          k_features=10, # the more features we want, the longer it will take to run\n",
    "          forward=True,  # for Step forward selection \n",
    "          floating=False,\n",
    "          verbose=2, # this indicates how much message to print out during intermediate steps\n",
    "          scoring='roc_auc',\n",
    "          cv=3)\n",
    "\n",
    "sfs.fit(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992a963f",
   "metadata": {},
   "source": [
    "From the output above, we can see that after adding the 8th feature, the performance begins to plateau. Adding the 9th and 10th feature did not increase the performance.\n",
    "\n",
    "If instead of selecting 10 features, we select more as the stopping criteria, we could have a clearer view of the progression of the performance vs number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a53856fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '14', '15', '19', '34', '43', '47', '52', '64', '68')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the index of the selected features\n",
    "sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abcd3565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 14, 15, 19, 34, 43, 47, 52, 64, 68)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indices of the selected features\n",
    "sfs.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "229f52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected features names\n",
    "selected_features = X_train.columns[list(sfs.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c7cb2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var_1', 'var_15', 'var_16', 'var_21', 'var_45', 'var_55', 'var_62',\n",
       "       'var_69', 'var_91', 'var_98'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def2fc47",
   "metadata": {},
   "source": [
    "## Compare performance of feature subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a651233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49c1df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.7119921185820277\n",
      "Test set\n",
      "Random Forests roc-auc: 0.6957598691250635\n"
     ]
    }
   ],
   "source": [
    "# Original data performance\n",
    "run_randomForests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bebf6bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.7129560989521158\n",
      "Test set\n",
      "Random Forests roc-auc: 0.7027726779668045\n"
     ]
    }
   ],
   "source": [
    "# Selected features data performance\n",
    "run_randomForests(X_train[selected_features], X_test[selected_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa0d43d",
   "metadata": {},
   "source": [
    "As you see, in this dataset, with 10 features we obtain a similar performance than that obtained using all variables in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbef647",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Let's now repeat the process but in the context of regression. With the house prices dataset from Kaggle, the aim is to predict the continuous target: House Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5158f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('house_price.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afabd006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 38)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In practice, feature selection should be done after data pre-processing,\n",
    "# so ideally, all the categorical variables are encoded into numbers,\n",
    "# and then you can assess how deterministic they are of the target\n",
    "\n",
    "# here for simplicity I will use only numerical variables\n",
    "# select numerical columns:\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_vars = list(data.select_dtypes(include=numerics).columns)\n",
    "data = data[numerical_vars]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c806e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 37), (438, 37))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(labels=['SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de8f2c",
   "metadata": {},
   "source": [
    "## Remove Correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc57bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  3\n"
     ]
    }
   ],
   "source": [
    "# find and remove correlated features\n",
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(X_train, 0.8)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8904276a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 34), (438, 34))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removed correlated features\n",
    "X_train.drop(labels=corr_features, axis=1, inplace=True)\n",
    "X_test.drop(labels=corr_features, axis=1, inplace=True)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10a3f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "520780c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:    4.1s finished\n",
      "\n",
      "[2022-06-02 11:24:05] Features: 1/20 -- score: 0.6448864917335085[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    1.5s finished\n",
      "\n",
      "[2022-06-02 11:24:06] Features: 2/20 -- score: 0.6946490592888616[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    1.3s finished\n",
      "\n",
      "[2022-06-02 11:24:08] Features: 3/20 -- score: 0.732141233157488[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:    1.2s finished\n",
      "\n",
      "[2022-06-02 11:24:09] Features: 4/20 -- score: 0.7423196453374377[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    1.2s finished\n",
      "\n",
      "[2022-06-02 11:24:10] Features: 5/20 -- score: 0.7489702405093164[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:    1.2s finished\n",
      "\n",
      "[2022-06-02 11:24:12] Features: 6/20 -- score: 0.7758111017343085[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    1.2s finished\n",
      "\n",
      "[2022-06-02 11:24:13] Features: 7/20 -- score: 0.7929944825142443[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    1.2s finished\n",
      "\n",
      "[2022-06-02 11:24:14] Features: 8/20 -- score: 0.8001157262251659[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    1.2s finished\n",
      "\n",
      "[2022-06-02 11:24:15] Features: 9/20 -- score: 0.8044090433577766[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    1.2s finished\n",
      "\n",
      "[2022-06-02 11:24:17] Features: 10/20 -- score: 0.804289727092082[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    1.1s finished\n",
      "\n",
      "[2022-06-02 11:24:18] Features: 11/20 -- score: 0.8049986229009377[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    1.1s finished\n",
      "\n",
      "[2022-06-02 11:24:19] Features: 12/20 -- score: 0.8079999508254482[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    1.1s finished\n",
      "\n",
      "[2022-06-02 11:24:20] Features: 13/20 -- score: 0.8086300806880972[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    1.0s finished\n",
      "\n",
      "[2022-06-02 11:24:21] Features: 14/20 -- score: 0.8079477641622586[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    1.0s finished\n",
      "\n",
      "[2022-06-02 11:24:23] Features: 15/20 -- score: 0.8108703232563307[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    1.0s finished\n",
      "\n",
      "[2022-06-02 11:24:24] Features: 16/20 -- score: 0.8288961238144907[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    1.0s finished\n",
      "\n",
      "[2022-06-02 11:24:25] Features: 17/20 -- score: 0.8294368373368814[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.9s finished\n",
      "\n",
      "[2022-06-02 11:24:26] Features: 18/20 -- score: 0.8366393151918193[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.9s finished\n",
      "\n",
      "[2022-06-02 11:24:27] Features: 19/20 -- score: 0.8360548783160211[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.8s finished\n",
      "\n",
      "[2022-06-02 11:24:28] Features: 20/20 -- score: 0.8306570411384331"
     ]
    }
   ],
   "source": [
    "# step forward feature selection\n",
    "\n",
    "sfs = SFS(RandomForestRegressor(n_estimators=10, n_jobs=2, random_state=10), \n",
    "           k_features=20, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='r2',\n",
    "           cv=2)\n",
    "\n",
    "sfs = sfs.fit(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b90b77",
   "metadata": {},
   "source": [
    "From the logs above, we see that after ~17 features, adding more features does not really improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30160520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 4, 5, 6, 7, 11, 12, 13, 14, 16, 17, 18, 19, 23, 24, 25, 28, 29, 30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "024d6a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "       'YearRemodAdd', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'Fireplaces',\n",
       "       'GarageCars', 'WoodDeckSF', '3SsnPorch', 'ScreenPorch', 'PoolArea'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the features \n",
    "X_train.columns[list(sfs.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64e1700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feats = X_train.columns[list(sfs.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bffa3f",
   "metadata": {},
   "source": [
    "# compare performance of the feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa665d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train random forests and evaluate the performance\n",
    "\n",
    "def run_randomForests(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=39, max_depth=4)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    print('Train set')\n",
    "    pred = rf.predict(X_train)\n",
    "    print('Random Forests roc-auc: {}'.format(r2_score(y_train, pred)))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict(X_test)\n",
    "    print('Random Forests roc-auc: {}'.format(r2_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bf02333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8629621682457452\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8246015925536159\n"
     ]
    }
   ],
   "source": [
    "# Selected features\n",
    "run_randomForests(X_train[selected_feats], X_test[selected_feats], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8d3887a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "Random Forests roc-auc: 0.8699152317492538\n",
      "Test set\n",
      "Random Forests roc-auc: 0.8190809813112794\n"
     ]
    }
   ],
   "source": [
    "# Original\n",
    "run_randomForests(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56d5d7f",
   "metadata": {},
   "source": [
    "We see that the algorithm with 20 features performs as well as that with 24 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69a48ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
